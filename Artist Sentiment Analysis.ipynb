{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import genius_token as gt\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob \n",
    "import SongLyrics_crendentials as cred\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_song_page_lookup(artist_id,token,page):\n",
    "    base_url = 'https://api.genius.com'\n",
    "    artist_url = base_url + '/artists/{}/songs'.format(artist_id)\n",
    "    headers = {'Authorization': 'Bearer ' + token}\n",
    "    params = {'sort':'popularity','page': page} # the current page\n",
    "    response = requests.get(artist_url, headers=headers,params=params).json()['response']['songs']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks up the artist into genius.com's API\n",
    "def artist_lookup(artist_name,token):\n",
    "    base_url = 'https://api.genius.com'\n",
    "    #third string is the token for access\n",
    "    headers = {'Authorization': 'Bearer ' + token}\n",
    "    search_url = base_url + '/search'\n",
    "    data = {'q':artist_name}\n",
    "    response = requests.get(search_url, data=data, headers=headers).json()['response']['hits']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls the Urls and song title out of the API's output\n",
    "def song_details(response):\n",
    "    urls = []\n",
    "    songs = []\n",
    "    artist = []\n",
    "    lyrics = []\n",
    "    #change this to be a dictionary\n",
    "    for song in response:\n",
    "        songs.append(song['title'])\n",
    "        urls.append(song['url']) \n",
    "        artist.append(song['primary_artist']['name'])\n",
    "    return songs,urls,artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapes the lyrics from the website, using the given urls\n",
    "def lyric_scraper(urls):\n",
    "    lyrics = []\n",
    "    for url in urls:\n",
    "        page = requests.get(url)\n",
    "        html = BeautifulSoup(page.text, 'html.parser')\n",
    "        div = html.find('div', class_=re.compile(\"^lyrics$|Lyrics__Root\"))\n",
    "        if div is not None:\n",
    "            lyrics.append(lyrics_cleaner(div.get_text()))\n",
    "        else:\n",
    "            lyrics.append('None')    \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls the verse labels out of the lyrics\n",
    "def lyrics_cleaner(song):\n",
    "    verse_labels_removed = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", song)\n",
    "    hyperlinks_removed = re.sub(r\"[0-9]+EmbedShare URLCopyEmbedCopy\",'',verse_labels_removed)\n",
    "    hyperlinks_removed = re.sub(r\"EmbedShare URLCopyEmbedCopy\",'',hyperlinks_removed)\n",
    "    cleaned_song= re.sub( r\"([A-Z])\", r\" \\1\",hyperlinks_removed)\n",
    "    return cleaned_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs a seniment analysis on the lyrics for the song, -1 is completely negative sentiment, 1 is completely positive    \n",
    "def artist_sentiment(artist_name,token):\n",
    "    songs = lyric_scraper(artist_name,token)\n",
    "    sentiments = []\n",
    "    for song in songs:\n",
    "        song_details = []\n",
    "        song_details.append(song[0])\n",
    "        blob = TextBlob(song[2])\n",
    "        song_details.append(blob.sentiment[0])\n",
    "        sentiments.append(song_details)\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_artist_songs(artist_id,token):\n",
    "    current_page = 1\n",
    "    next_page = True\n",
    "    songs = []\n",
    "    while next_page is True:\n",
    "        page_songs = (artist_song_page_lookup(artist_id,token,current_page))\n",
    "        unique_songs = remastered_song_remover(page_songs,artist_id)\n",
    "        songs.extend(unique_songs)\n",
    "        current_page += 1\n",
    "        if len(page_songs) == 0:\n",
    "            next_page = False\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "songdb = cred.client[\"songs\"]\n",
    "songcol = songdb[\"song\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_lists(artist_id,token):\n",
    "    response = get_all_artist_songs(artist_id,token)\n",
    "    songs,urls,artist = song_details(response)\n",
    "    lyrics = lyric_scraper(urls)\n",
    "    songs,urls,artist,lyrics = blank_song_remover(songs,urls,artist,lyrics)\n",
    "    return songs,urls,artist,lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remastered_song_remover(page_songs, artist_id):\n",
    "    duplicate_flags = ['remix','sound track', 'live','music-video','version', 'grammys', 'mix', 'edit', 'vma', 'acoustic', 'demo', 'statement', 'radio', 'session', 'awards', 'extended', 'setlist']\n",
    "    songs_with_lyrics = [song for song in page_songs if song['url'].endswith('-lyrics')]\n",
    "    unique_songs = [song for song in songs_with_lyrics if not any(flag in song['url'] for flag in duplicate_flags)]\n",
    "    unique_songs = [song for song in unique_songs if song['primary_artist']['id'] == artist_id]\n",
    "    return unique_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_song_remover(songs,urls,artist,lyrics):\n",
    "    i = 0\n",
    "    while i < len(lyrics):\n",
    "        if lyrics[i] == 'None':\n",
    "            songs.pop(i)\n",
    "            urls.pop(i)\n",
    "            artist.pop(i)\n",
    "            lyrics.pop(i)\n",
    "            i = i+1\n",
    "        else:\n",
    "            i = i+1\n",
    "    return songs,urls,artist,lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_remover(song):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    lyrics = song.lower()\n",
    "    word_list = [word for word in lyrics.split() if word not in stop_words]\n",
    "    return word_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(lyrics):\n",
    "    word_dict = {}\n",
    "    unique_words = stopword_remover(lyrics)\n",
    "    for word in unique_words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] = word_dict[word]+1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector1, vector2):\n",
    "    \n",
    "    # Get the common characters between the two character sets\n",
    "    common_characters = vector1[1].intersection(vector2[1])\n",
    "    # Sum of the product of each intersection character.\n",
    "    product_summation = sum(vector1[0][character] * vector2[0]                  [character] for character in common_characters)\n",
    "    # Gets the length of each vector from the word2vec output.\n",
    "    length = vector1[2] * vector2[2]\n",
    "    # Calculates cosine similarity and rounds the value to ndigits decimal places.\n",
    "    if length == 0:\n",
    "        # Set value to 0 if word is empty.\n",
    "        similarity = 0\n",
    "    else:\n",
    "        similarity = product_summation/length\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(song_lyrics):\n",
    "    counted_words = word_counter(song_lyrics)\n",
    "    word_set = set(counted_words)\n",
    "    length = math.sqrt(sum(c*c for c in counted_words.values()))\n",
    "    return counted_words,word_set,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(lyrics,similarity_threshold,songs):\n",
    "    results = []\n",
    "    vector_list = [word2vec(song) for song in lyrics]\n",
    "    for i in range(len(vector_list)):\n",
    "        vector_1 = vector_list[i]\n",
    "        for j in range(i+1,len(vector_list)):\n",
    "            vector_2 = vector_list[j]\n",
    "            similarity_score= cos_sim(vector_1,vector_2)\n",
    "            if 1 >= similarity_score >= similarity_threshold:\n",
    "                results.append([songs[i], songs[j], similarity_score,i,j])\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_db(url,data):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs,urls,artist,lyrics = song_lists(447,gt.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Bad Romance', 'Bad Romance (Chew Fu H1N1 Fix)', 0.839993314686811, 1, 175], ['Million Reasons', 'Million Reasons (Work Tape)', 0.9999999999999999, 5, 140], ['G.U.Y.', 'G.U.Y an ARTPOP film', 0.8407129282734064, 6, 174], ['The Cure', 'Tokyo', 0.8566656716767037, 9, 183], ['Yoü and I', 'Yoü and I (Joe Biden Election Night Rally 2020)', 0.7821058306669801, 30, 221], ['LoveGame', 'LoveGame (Chew Fu Ghettohouse Fix)', 0.8037503166735607, 37, 179], ['Angel Down', 'Angel Down (Work Tape)', 0.9270519189464063, 53, 95], ['Boys Boys Boys', 'Boys Boys Boys (Manhattan Clique)', 0.9655490337855374, 69, 203], ['The Manifesto of Mother Monster', 'Born This Way Monologue', 0.8074695559742581, 103, 119], ['In Like With You', 'From the USA', 1.0, 151, 218], ['Maren', 'Temple', 1.0, 158, 189], ['Maren', 'Cut The Cake', 1.0, 158, 198], ['Maren', 'John’s Song', 1.0, 158, 222], ['Maren', 'No One Can Know', 1.0, 158, 223], ['Maren', 'Walk The Road', 1.0, 158, 224], ['Maren', 'In a Dream', 1.0, 158, 227], ['Krypton Girl*', 'Lost Children', 1.0, 177, 188], ['Krypton Girl*', 'Metropolis', 1.0, 177, 190], ['Krypton Girl*', 'N M N', 1.0, 177, 191], ['Krypton Girl*', 'Talk 2 Me*', 1.0, 177, 195], ['Krypton Girl*', 'Plastic man', 1.0, 177, 204], ['Krypton Girl*', 'Searching*', 1.0, 177, 205], ['Krypton Girl*', 'Lady Stones', 1.0, 177, 207], ['Lost Children', 'Metropolis', 1.0, 188, 190], ['Lost Children', 'N M N', 1.0, 188, 191], ['Lost Children', 'Talk 2 Me*', 1.0, 188, 195], ['Lost Children', 'Plastic man', 1.0, 188, 204], ['Lost Children', 'Searching*', 1.0, 188, 205], ['Lost Children', 'Lady Stones', 1.0, 188, 207], ['Temple', 'Cut The Cake', 1.0, 189, 198], ['Temple', 'John’s Song', 1.0, 189, 222], ['Temple', 'No One Can Know', 1.0, 189, 223], ['Temple', 'Walk The Road', 1.0, 189, 224], ['Temple', 'In a Dream', 1.0, 189, 227], ['Metropolis', 'N M N', 1.0, 190, 191], ['Metropolis', 'Talk 2 Me*', 1.0, 190, 195], ['Metropolis', 'Plastic man', 1.0, 190, 204], ['Metropolis', 'Searching*', 1.0, 190, 205], ['Metropolis', 'Lady Stones', 1.0, 190, 207], ['N M N', 'Talk 2 Me*', 1.0, 191, 195], ['N M N', 'Plastic man', 1.0, 191, 204], ['N M N', 'Searching*', 1.0, 191, 205], ['N M N', 'Lady Stones', 1.0, 191, 207], ['Talk 2 Me*', 'Plastic man', 1.0, 195, 204], ['Talk 2 Me*', 'Searching*', 1.0, 195, 205], ['Talk 2 Me*', 'Lady Stones', 1.0, 195, 207], ['Cut The Cake', 'John’s Song', 1.0, 198, 222], ['Cut The Cake', 'No One Can Know', 1.0, 198, 223], ['Cut The Cake', 'Walk The Road', 1.0, 198, 224], ['Cut The Cake', 'In a Dream', 1.0, 198, 227], ['Plastic man', 'Searching*', 1.0, 204, 205], ['Plastic man', 'Lady Stones', 1.0, 204, 207], ['Searching*', 'Lady Stones', 1.0, 205, 207], ['John’s Song', 'No One Can Know', 1.0, 222, 223], ['John’s Song', 'Walk The Road', 1.0, 222, 224], ['John’s Song', 'In a Dream', 1.0, 222, 227], ['No One Can Know', 'Walk The Road', 1.0, 223, 224], ['No One Can Know', 'In a Dream', 1.0, 223, 227], ['Walk The Road', 'In a Dream', 1.0, 224, 227]]\n"
     ]
    }
   ],
   "source": [
    "print(get_similarity(lyrics,.75,songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://genius.com/Lady-gaga-no-one-can-know-lyrics\n"
     ]
    }
   ],
   "source": [
    "print(urls[223])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroku_url = 'https://git.heroku.com/artistsentiment.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchModuleError",
     "evalue": "Can't load plugin: sqlalchemy.dialects:https",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchModuleError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e2743ebef91b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msessionmaker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheroku_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mecho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# attach the data frame (df) to the database with a name of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# table; the name can be whatever you like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\__init__.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"plugins\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mentrypoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_entrypoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mdialect_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dialect_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\url.py\u001b[0m in \u001b[0;36m_get_entrypoint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrivername\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;31m# check for legacy dialects that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# would return a module with 'dialect' as the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         raise exc.NoSuchModuleError(\n\u001b[0m\u001b[0;32m    269\u001b[0m             \u001b[1;34m\"Can't load plugin: %s:%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         )\n",
      "\u001b[1;31mNoSuchModuleError\u001b[0m: Can't load plugin: sqlalchemy.dialects:https"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "engine = create_engine(heroku_url, echo = False)\n",
    "# attach the data frame (df) to the database with a name of the \n",
    "# table; the name can be whatever you like\n",
    "data = [1]\n",
    "data.to_sql('fake_data', con = engine, if_exists='append')\n",
    "# run a quick test \n",
    "print(engine.execute('SELECT * FROM fake_data').fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
