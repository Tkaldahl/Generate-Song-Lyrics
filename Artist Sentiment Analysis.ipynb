{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import genius_token as gt\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob \n",
    "import SongLyrics_crendentials as cred\n",
    "import nltk\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_song_page_lookup(artist_id,token,page):\n",
    "    base_url = 'https://api.genius.com'\n",
    "    artist_url = base_url + '/artists/{}/songs'.format(artist_id)\n",
    "    headers = {'Authorization': 'Bearer ' + token}\n",
    "    params = {'sort':'popularity','page': page} # the current page\n",
    "    response = requests.get(artist_url, headers=headers,params=params).json()['response']['songs']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks up the artist into genius.com's API\n",
    "def artist_lookup(artist_name,token):\n",
    "    base_url = 'https://api.genius.com'\n",
    "    #third string is the token for access\n",
    "    headers = {'Authorization': 'Bearer ' + token}\n",
    "    search_url = base_url + '/search'\n",
    "    data = {'q':artist_name}\n",
    "    response = requests.get(search_url, data=data, headers=headers).json()['response']['hits']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls the Urls and song title out of the API's output\n",
    "def song_details(response):\n",
    "    urls = []\n",
    "    songs = []\n",
    "    artist = []\n",
    "    lyrics = []\n",
    "    #change this to be a dictionary\n",
    "    for song in response:\n",
    "        songs.append(song['title'])\n",
    "        urls.append(song['url']) \n",
    "        artist.append(song['primary_artist']['name'])\n",
    "    return songs,urls,artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapes the lyrics from the website, using the given urls\n",
    "def lyric_scraper(urls):\n",
    "    lyrics = []\n",
    "    for url in urls:\n",
    "        page = requests.get(url)\n",
    "        html = BeautifulSoup(page.text, 'html.parser')\n",
    "        div = html.find('div', class_=re.compile(\"^lyrics$|Lyrics__Root\"))\n",
    "        if div is not None:\n",
    "            lyrics.append(lyrics_cleaner(div.get_text()))\n",
    "        else:\n",
    "            lyrics.append('None')    \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls the verse labels out of the lyrics\n",
    "def lyrics_cleaner(song):\n",
    "    verse_labels_removed = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", song)\n",
    "    hyperlinks_removed = re.sub(r\"[0-9]+EmbedShare URLCopyEmbedCopy\",'',verse_labels_removed)\n",
    "    hyperlinks_removed = re.sub(r\"EmbedShare URLCopyEmbedCopy\",'',hyperlinks_removed)\n",
    "    cleaned_song= re.sub( r\"([A-Z])\", r\" \\1\",hyperlinks_removed)\n",
    "    return cleaned_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs a seniment analysis on the lyrics for the song, -1 is completely negative sentiment, 1 is completely positive    \n",
    "def artist_sentiment(artist_name,token):\n",
    "    songs = lyric_scraper(artist_name,token)\n",
    "    sentiments = []\n",
    "    for song in songs:\n",
    "        song_details = []\n",
    "        song_details.append(song[0])\n",
    "        blob = TextBlob(song[2])\n",
    "        song_details.append(blob.sentiment[0])\n",
    "        sentiments.append(song_details)\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_artist_songs(artist_id,token):\n",
    "    current_page = 1\n",
    "    next_page = True\n",
    "    songs = []\n",
    "    while next_page is True:\n",
    "        page_songs = (artist_song_page_lookup(artist_id,token,current_page))\n",
    "        unique_songs = remastered_song_remover(page_songs,artist_id)\n",
    "        songs.extend(unique_songs)\n",
    "        current_page += 1\n",
    "        if len(page_songs) == 0:\n",
    "            next_page = False\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "songdb = cred.client[\"songs\"]\n",
    "songcol = songdb[\"song\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_lists(artist_id,token):\n",
    "    response = get_all_artist_songs(artist_id,token)\n",
    "    songs,urls,artist = song_details(response)\n",
    "    lyrics = lyric_scraper(urls)\n",
    "    songs,urls,artist,lyrics = blank_song_remover(songs,urls,artist,lyrics)\n",
    "    return songs,urls,artist,lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remastered_song_remover(page_songs, artist_id):\n",
    "    duplicate_flags = ['remix','sound track', 'live','music-video','version', 'grammys', 'mix', 'edit', 'vma', 'acoustic', 'demo', 'statement', 'radio', 'session', 'awards', 'extended', 'setlist']\n",
    "    songs_with_lyrics = [song for song in page_songs if song['url'].endswith('-lyrics')]\n",
    "    unique_songs = [song for song in songs_with_lyrics if not any(flag in song['url'] for flag in duplicate_flags)]\n",
    "    unique_songs = [song for song in unique_songs if song['primary_artist']['id'] == artist_id]\n",
    "    return unique_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_song_remover(songs,urls,artist,lyrics):\n",
    "    i = 0\n",
    "    while i < len(lyrics):\n",
    "        if lyrics[i] == 'None':\n",
    "            songs.pop(i)\n",
    "            urls.pop(i)\n",
    "            artist.pop(i)\n",
    "            lyrics.pop(i)\n",
    "            i = i+1\n",
    "        else:\n",
    "            i = i+1\n",
    "    return songs,urls,artist,lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_remover(song):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    lyrics = song.lower()\n",
    "    word_list = [word for word in lyrics.split() if word not in stop_words]\n",
    "    return word_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(lyrics):\n",
    "    word_dict = {}\n",
    "    unique_words = stopword_remover(lyrics)\n",
    "    for word in unique_words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] = word_dict[word]+1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector1, vector2):\n",
    "    \n",
    "    # Get the common characters between the two character sets\n",
    "    common_characters = vector1[1].intersection(vector2[1])\n",
    "    # Sum of the product of each intersection character.\n",
    "    product_summation = sum(vector1[0][character] * vector2[0]                  [character] for character in common_characters)\n",
    "    # Gets the length of each vector from the word2vec output.\n",
    "    length = vector1[2] * vector2[2]\n",
    "    # Calculates cosine similarity and rounds the value to ndigits decimal places.\n",
    "    if length == 0:\n",
    "        # Set value to 0 if word is empty.\n",
    "        similarity = 0\n",
    "    else:\n",
    "        similarity = product_summation/length\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(song_lyrics):\n",
    "    counted_words = word_counter(song_lyrics)\n",
    "    word_set = set(counted_words)\n",
    "    length = math.sqrt(sum(c*c for c in counted_words.values()))\n",
    "    return counted_words,word_set,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(lyrics,similarity_threshold,songs):\n",
    "    results = []\n",
    "    vector_list = [word2vec(song) for song in lyrics]\n",
    "    for i in range(len(vector_list)):\n",
    "        vector_1 = vector_list[i]\n",
    "        for j in range(i+1,len(vector_list)):\n",
    "            vector_2 = vector_list[j]\n",
    "            similarity_score= cos_sim(vector_1,vector_2)\n",
    "            if 1 >= similarity_score >= similarity_threshold:\n",
    "                results.append([songs[i], songs[j], similarity_score,i,j])\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
